\appendix

\chapter{A Primer on Probability}

% a section to be written

% the idea is to use the fact that
% the events are independent, so you can take a product, but the probability
% in which you are interested is the complement, so you take 1 - product.
\emph{The get-away.} You plan to rob four banks and then escape
  to Mexico. In each robbery the probability of getting caught is 1/3,
  and the outcome of each robbery is independent of that of the
  others. What is the probability that you end up in jail?

  Since the outcome of each robbery is independent, the probability of
  \emph{not} ending up in jail is the probability that you never get
  caught.
\[
P(\text{don't get caught}) = 
\left(\frac{2}{3}\right)\left(\frac{2}{3}\right)\left(\frac{2}{3}\right)\left(\frac{2}{3}\right) = 
\frac{16}{81}
\]
and so the probability of ending up in jail is $1 - \frac{16}{81} \approx 0.8$.

%% probability and independence of events
Suppose that the probability of exposure to the flu during an epidemic
is 0.6. Experience has shown that a serum is 80\% successful in
preventing an inoculated person from acquiring the flu, if exposed. A
person not inoculated faces a probability of 0.9 of acquiring the flu
if exposed. Two persons, one inoculated and one not, are capable of
performing a highly specialized task in a business.  Assume that they
are not at the same location, are not in contact with the same people,
and cannot expose each other. What is the probability that at least
one will get the flu?

Let $A$ be the event that the inoculated person gets the flu, and let $B$
be the event that the person who is not inoculated gets the flu. The probability
that at least one of them gets the flu is
\[ P(A \cup B) \]
From the problem description we can safely say
that the events $A$ and $B$ are independent. Also note that a
person's exposure to the flu is independent of inoculation, so that
\[ P(A) = (.6)(.2) = .12 \qquad \text{and} \qquad P(B) = (.6)(.9) = .54 \]
Then,
\begin{align*}
  P(A \cup B) &= P(A) + P(B) - P(A \cap B)\\
              &= P(A) + P(B) - P(A)P(B)\\
              &= .12 + .54 - (.12)(.54)\\
              &= .5952
\end{align*}

\emph{Conditional probability}.
In a population of 100,000 females, 89.835\% can expect
to live to age 60, while 57.062\% can expect to live to age
80. Given that a woman is 60, what is the probability that she lives
to age 80?

We can use the definition of conditional
probability. Let $E$ be the event that a woman lives to be 60, and
let $F$ be the event that a woman lives to be 80.
\[
P(F \mid E) = \frac{P(F,E)}{P(E)} = \frac{P(E \mid F)P(F)}{P(E)} = \frac{1 \times .5706}{.8984} = .6352
\]

Also, read this answer that was taken from Grinstead and Snell. It
nicely describes the idea of conditional probability.

\begin{quote}
  The original sample space can be thought of as a set of 100,000
  females. The events E and F are the subsets of the sample space
  consisting of all women who live at least 60 years, and at least 80
  years, respectively. We consider E to be the new sample space, and
  note that F is a subset of E. Thus, the size of E is 89,835, and the
  size of F is 57,062.  So, the probability in question equals
  57,062/89,835 = .6352. Thus, a woman who is 60 has a 63.52\% chance
  of living to age 80.
\end{quote}


\emph{Baye's formula.}
An automobile manufacturer makes cars with three types of
  engines. Of all cars made by this manufacturer, 45\% are hybrids
  (gasoline-electric), 35\% are gasoline, and 20\% are diesel. From
  past data, it is known that 5\% of the cars with hybrid engines fail
  the emissions test, while 12\% of cars with gasoline engines and
  25\% of cars with diesel engines fail the test. A record of a failed
  emissions test is selected at random, what is the probability that
  it is for a car with a diesel engine?
  
\begin{center}
\begin{tabular}{lrr}
    engine type & \% of cars & \% failed \\ \hline
    hybrid & 45 & 5 \\
    gasoline & 35 & 12 \\
    diesel & 20 & 25
\end{tabular}
\end{center}
  Let $H$ represent the event that a car has a hybrid
  engine. Similarly, $G$ and $D$ represent gasoline and diesel. Let
  $F$ represent the event that a car failed the emissions test. We
  want to know $P(D\mid F)$.
\begin{align*}
    P(D\mid F) &= \frac{P(D \cap F)}{P(F)} \\
    &= \frac{P(F \mid D)P(D)}{P(F \mid H)P(H) + P(F \mid G)P(G) + P(F \mid D)P(D)} \\
    &= \frac{(.25)(.20)}{(.05)(.45) + (.12)(.35) + (.25)(.20)} \\
    &= .437
\end{align*}

\emph{Updating a prior belief with new information or Bayesian updating.}
Your prior probability that a certain coin is biased to always land
heads up is 0.1. Now you toss the coin three times and observe that it
lands heads up every time. What is your posterior probability that the
coin is biased to always land heads up?  Use Baye's formula to compute
the posterior probability. Use the Binomial distribution to compute
the likelihood.

Let $B$ indicate that the coin is biased, and let $3H$ indicate an
outcome of three heads. We are given (or can determine)
\[
P(B) = 0.1, \quad P(3H \mid \overline{B}) = \left(\frac{1}{2}\right)^3, \quad P(3H \mid B) = 1
\]
We can use Baye's Theorem to compute the posterior probability.
\begin{align*}
P(B \mid 3H) &= \frac{P(B~\text{and}~3H)}{P(3H)} \\
&= \frac{P(3H \mid B)P(B)}{P(3H \mid B)P(B) + P(3H \mid \overline{B})P(\overline{B})} \\
&= \frac{(1)(0.1)}{(1)(0.1) + \left(\frac{1}{8}\right)(.9)} \\
&\approx 0.47
\end{align*}

\chapter{Standard Normal Distribution}

Standard Normal random
  variables are denoted by an upper case $Z$. 
  \[ Z \sim \mathcal{N}(0,1) \]
The cumulative distribution function (CDF) is denoted
  $\Phi(z)$. It is represented by the area under the curve and to the
  left of $z$.
  \[
  \Phi(z) = P(Z \leq z) = \int_{-\infty}^z \frac{1}{\sqrt{2\pi}}e^{-u^2/2}\, du
  \]


\begin{center}
\begin{tikzpicture}
\begin{axis}[
  no markers, domain=-4:4,samples=100,
  height=5cm, width=9cm,
  axis x line*=bottom,
  axis y line=none,
  xtick={-4,-3,-2,-1,0,1,2,3,4}, ytick=\empty,
  extra x ticks={1.5},
  extra x tick labels={$z$},
  enlargelimits=false
  ]
  
\addplot [fill, color=gray!50, opacity=0.5, domain=-3.5:1.5] {gauss(0,1)} \closedcycle;
\addplot [thick] {gauss(0,1)};

\draw[thin] (1.5,0) -- (1.5,0.1295176);
\draw (-2,.2) node[anchor=east] (p1) {$\Phi(z)$};
\draw (-.2,.13) node (p2) {};
\draw[-] (p1) -- (p2);

\end{axis}
\end{tikzpicture}
\end{center}

The probabilities in the table on the opposite page were generated
using R. For example, \texttt{pnorm(1.31)} returns 0.9049. Given an
area, one can obtain the corresponding quantile by working backwards
through the table. Using R, \texttt{qnorm(.9)} returns 1.28.

\begingroup
\renewcommand*{\arraystretch}{1.1}
\newcolumntype{Z}{>{\raggedleft\arraybackslash}X}
{\small
\begin{tabularx}{\textwidth}{p{0.5cm}ZZZZZZZZZZ} \hline
$z$ & 0.00 & 0.01 & 0.02 & 0.03 & 0.04 & 0.05 & 0.06 & 0.07 & 0.08 & 0.09 \\ \hline
0.0& 0.5000& 0.5040& 0.5080& 0.5120& 0.5160& 0.5199& 0.5239& 0.5279& 0.5319& 0.5359\\ 
0.1& 0.5398& 0.5438& 0.5478& 0.5517& 0.5557& 0.5596& 0.5636& 0.5675& 0.5714& 0.5753\\ 
0.2& 0.5793& 0.5832& 0.5871& 0.5910& 0.5948& 0.5987& 0.6026& 0.6064& 0.6103& 0.6141\\ 
0.3& 0.6179& 0.6217& 0.6255& 0.6293& 0.6331& 0.6368& 0.6406& 0.6443& 0.6480& 0.6517\\ 
0.4& 0.6554& 0.6591& 0.6628& 0.6664& 0.6700& 0.6736& 0.6772& 0.6808& 0.6844& 0.6879\\ 
0.5& 0.6915& 0.6950& 0.6985& 0.7019& 0.7054& 0.7088& 0.7123& 0.7157& 0.7190& 0.7224\\ 
\rowcolor[gray]{0.8}
0.6& 0.7257& 0.7291& 0.7324& 0.7357& 0.7389& 0.7422& 0.7454& 0.7486& 0.7517& 0.7549\\ 
\rowcolor[gray]{0.8}
0.7& 0.7580& 0.7611& 0.7642& 0.7673& 0.7704& 0.7734& 0.7764& 0.7794& 0.7823& 0.7852\\ 
\rowcolor[gray]{0.8}
0.8& 0.7881& 0.7910& 0.7939& 0.7967& 0.7995& 0.8023& 0.8051& 0.8078& 0.8106& 0.8133\\ 
\rowcolor[gray]{0.8}
0.9& 0.8159& 0.8186& 0.8212& 0.8238& 0.8264& 0.8289& 0.8315& 0.8340& 0.8365& 0.8389\\ 
\rowcolor[gray]{0.8}
1.0& 0.8413& 0.8438& 0.8461& 0.8485& 0.8508& 0.8531& 0.8554& 0.8577& 0.8599& 0.8621\\ 
1.1& 0.8643& 0.8665& 0.8686& 0.8708& 0.8729& 0.8749& 0.8770& 0.8790& 0.8810& 0.8830\\ 
1.2& 0.8849& 0.8869& 0.8888& 0.8907& 0.8925& 0.8944& 0.8962& 0.8980& 0.8997& 0.9015\\ 
1.3& 0.9032& 0.9049& 0.9066& 0.9082& 0.9099& 0.9115& 0.9131& 0.9147& 0.9162& 0.9177\\ 
1.4& 0.9192& 0.9207& 0.9222& 0.9236& 0.9251& 0.9265& 0.9279& 0.9292& 0.9306& 0.9319\\ 
1.5& 0.9332& 0.9345& 0.9357& 0.9370& 0.9382& 0.9394& 0.9406& 0.9418& 0.9429& 0.9441\\ 
\rowcolor[gray]{0.8}
1.6& 0.9452& 0.9463& 0.9474& 0.9484& 0.9495& 0.9505& 0.9515& 0.9525& 0.9535& 0.9545\\ 
\rowcolor[gray]{0.8}
1.7& 0.9554& 0.9564& 0.9573& 0.9582& 0.9591& 0.9599& 0.9608& 0.9616& 0.9625& 0.9633\\ 
\rowcolor[gray]{0.8}
1.8& 0.9641& 0.9649& 0.9656& 0.9664& 0.9671& 0.9678& 0.9686& 0.9693& 0.9699& 0.9706\\ 
\rowcolor[gray]{0.8}
1.9& 0.9713& 0.9719& 0.9726& 0.9732& 0.9738& 0.9744& 0.9750& 0.9756& 0.9761& 0.9767\\ 
\rowcolor[gray]{0.8}
2.0& 0.9772& 0.9778& 0.9783& 0.9788& 0.9793& 0.9798& 0.9803& 0.9808& 0.9812& 0.9817\\ 
2.1& 0.9821& 0.9826& 0.9830& 0.9834& 0.9838& 0.9842& 0.9846& 0.9850& 0.9854& 0.9857\\ 
2.2& 0.9861& 0.9864& 0.9868& 0.9871& 0.9875& 0.9878& 0.9881& 0.9884& 0.9887& 0.9890\\ 
2.3& 0.9893& 0.9896& 0.9898& 0.9901& 0.9904& 0.9906& 0.9909& 0.9911& 0.9913& 0.9916\\ 
2.4& 0.9918& 0.9920& 0.9922& 0.9925& 0.9927& 0.9929& 0.9931& 0.9932& 0.9934& 0.9936\\ 
2.5& 0.9938& 0.9940& 0.9941& 0.9943& 0.9945& 0.9946& 0.9948& 0.9949& 0.9951& 0.9952\\ 
\rowcolor[gray]{0.8}
2.6& 0.9953& 0.9955& 0.9956& 0.9957& 0.9959& 0.9960& 0.9961& 0.9962& 0.9963& 0.9964\\ 
\rowcolor[gray]{0.8}
2.7& 0.9965& 0.9966& 0.9967& 0.9968& 0.9969& 0.9970& 0.9971& 0.9972& 0.9973& 0.9974\\ 
\rowcolor[gray]{0.8}
2.8& 0.9974& 0.9975& 0.9976& 0.9977& 0.9977& 0.9978& 0.9979& 0.9979& 0.9980& 0.9981\\ 
\rowcolor[gray]{0.8}
2.9& 0.9981& 0.9982& 0.9982& 0.9983& 0.9984& 0.9984& 0.9985& 0.9985& 0.9986& 0.9986\\ 
\rowcolor[gray]{0.8}
3.0& 0.9987& 0.9987& 0.9987& 0.9988& 0.9988& 0.9989& 0.9989& 0.9989& 0.9990& 0.9990\\ 
3.1& 0.9990& 0.9991& 0.9991& 0.9991& 0.9992& 0.9992& 0.9992& 0.9992& 0.9993& 0.9993\\ 
3.2& 0.9993& 0.9993& 0.9994& 0.9994& 0.9994& 0.9994& 0.9994& 0.9995& 0.9995& 0.9995\\ 
3.3& 0.9995& 0.9995& 0.9995& 0.9996& 0.9996& 0.9996& 0.9996& 0.9996& 0.9996& 0.9997\\ 
\end{tabularx}
}
\endgroup
